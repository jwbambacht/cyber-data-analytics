{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import profiling as prof\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "import itertools\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from math import sqrt\n",
    "\n",
    "data9 = prof.load_data(\"data/capture20110817.binetflow.txt\")\n",
    "data10 = prof.load_data(\"data/capture20110818-2.binetflow.txt\")\n",
    "data11 = prof.load_data(\"data/capture20110818.binetflow.txt\")\n",
    "data12 = prof.load_data(\"data/capture20110819.binetflow.txt\")\n",
    "pdata9 = prof.pre_process(data9,9)\n",
    "pdata10 = prof.pre_process(data10,10)\n",
    "pdata11 = prof.pre_process(data11,11)\n",
    "pdata12 = prof.pre_process(data12,12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We preprocess the data for scenario 9 to 12 and discretize the protocol feature the same way we did as the previous tasks. Scenario 9 will be the 'training' scenario, in which we will choose a suitable threshold for the distance calculation in the other scenarios. This threshold separates the new predicted infected hosts from normal hosts. First an infected source/host is selected from scenario 9, in this case with the most netflows in the dataset to train as best as possible. We then calculate all 3-grams in the flows from this host and count the occurences, resulting in a profile for this host. Instead of using a timed sliding-window, the unique hosts are grouped and profiles are created from counts of 3-grams. The choice for 3-grams is based on the fact that the possible combinations of 2-grams are quite low (only 4 combinations) and there are not enough flows originating from the unique hosts for using 4-grams. \n",
    "\n",
    "For each unique host we calculate the 3-grams profile the same way as we did for the selected host, and additionaly we calculate the cosine distance in relation to the selected host. At the end of this iteration the distance between the initially selected host and all unique hosts is determined. We must choose a threshold that separates the infected and normal hosts as correctyly as possible and additionaly optimizes the number of newly identified infected hosts. Part of the hosts in the dataset are labeled as infected or normal, while there is a part that is not labeled yet and thus to be identified. A grid search is applied for a threshold of 0 to 0.25 (cosine distance). The results show that with a threshold of 0.18 there are 12 (out of 19 unidentified) new infections identified at cost of a couple of true positives and false positives, dropping the accuracy to 62.5%. The false positives indicate hosts that are labeled as infected while they are not. It is thus important to keep this number as low as possible in comparison to the number of newly identified infected hosts.\n",
    "\n",
    "With this chosen threshold we can do the same for the other three scenarios. We find that the results with this threshold do not deviate much for the other scenarios. We identify zero, seven and six newly identified infections to respectively scenario 9, 10 and 11, at cost of one, one and five false positives. We can thus conclude that by profiling using n-grams new infected hosts can be detected. However, the more the threshold is on 'edge', the more this results in an increase in false positives. This is a trade-off someone should be willing to make (or not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Lengths must match to compare",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e92c0f35efef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# This is the 3-gram profile of this host\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mselected_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_infected_host\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscenario\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mfiltered_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscretized_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdiscretized_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSourceAddress\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mselected_source\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mngram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0mrvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomparison_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;31m#  The ambiguous case is object-dtype.  See GH#27803\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Lengths must match to compare\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_extension_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Lengths must match to compare"
     ]
    }
   ],
   "source": [
    "scenarios = [9, 10, 11, 12]\n",
    "grid_search = pd.DataFrame(columns=[\"Scenario\", \"Threshold\",\"Unknown\",\"TP\",\"FP\",\"FN\",\"TN\",\"Accuracy\",\"NEW_INFECTIONS\"])\n",
    "\n",
    "for scenario in scenarios:\n",
    "    if scenario == 9:\n",
    "        pdata = pdata9.copy()\n",
    "    elif scenario == 10:\n",
    "        pdata = pdata10.copy()\n",
    "    elif scenario == 11:\n",
    "        pdata = pdata11.copy()\n",
    "    elif scenario == 12:\n",
    "        pdata = pdata12.copy() \n",
    "\n",
    "    # Feature to use, including its optimal binsize, and discretized to be used for n-grams\n",
    "    feature = \"Protocol\"\n",
    "    nbins = 3\n",
    "\n",
    "    discretized_data = pd.DataFrame()\n",
    "    discretized_data[\"StartTime\"] = pdata[\"StartTime\"].copy()\n",
    "    discretized_data[\"SourceAddress\"] = pdata[\"SourceAddress\"].copy()\n",
    "    discretized_data[\"DestinationAddress\"] = pdata[\"DestinationAddress\"].copy()\n",
    "    pdata[\"Protocol\"] = prof.encode_feature(pdata[\"Protocol\"])\n",
    "    discretized_data[feature], binsedges_infected = prof.discretize_feature(pdata, feature, nbins, \"kmeans\")\n",
    "\n",
    "    # Select source with most entries in given dataset to deliver most reliable n-gram profile\n",
    "    # Determine list of all possible n-grams for selected host\n",
    "    # This is the 3-gram profile of this host\n",
    "    selected_source = prof.select_infected_host(pdata,scenario)\n",
    "    filtered_source = discretized_data.loc[discretized_data.SourceAddress == selected_source]\n",
    "\n",
    "    ngram = 3\n",
    "    all_n_grams = list(itertools.product(*[['0','1','2'],['0','1','2'],['0','1','2']]))\n",
    "\n",
    "    n_grams = pd.Index(list(ngrams(filtered_source[feature].astype(str),ngram)))\n",
    "    n_grams_counts = [0]*len(all_n_grams)\n",
    "\n",
    "    for i in range(len(n_grams.value_counts())):\n",
    "        n_gram = n_grams.value_counts()\n",
    "        index_all_n_grams = all_n_grams.index(n_gram.index[i])\n",
    "        n_grams_counts[index_all_n_grams] = n_gram[i]\n",
    "\n",
    "    # Group netflows by source address (host) because we are interested in modeling per-host behavior\n",
    "    unique_sources = pdata.groupby([\"SourceAddress\"]).size().reset_index()\n",
    "\n",
    "    # Calculate the distance for every other source compared to the selected source/host\n",
    "    distances = [100]*len(unique_sources)\n",
    "    n_gram_count_list = list()\n",
    "\n",
    "    for i in range(len(unique_sources)):\n",
    "        source = unique_sources.iloc[i]\n",
    "\n",
    "        filtered = discretized_data.loc[discretized_data.SourceAddress == source.SourceAddress]\n",
    "        n_grams_source = pd.Index(list(ngrams(filtered[feature].astype(str),ngram)))\n",
    "        n_grams_source_counts = [0]*len(all_n_grams)\n",
    "\n",
    "        for j in range(len(n_grams_source.value_counts())):\n",
    "            n_gram = n_grams_source.value_counts()\n",
    "            index_all_n_grams = all_n_grams.index(n_gram.index[j])\n",
    "            n_grams_source_counts[index_all_n_grams] = n_gram[j]\n",
    "\n",
    "\n",
    "        # Cosine distance between selected host and other hosts\n",
    "        if np.sum(n_grams_source_counts) == 0:\n",
    "            distances[i] = 1\n",
    "        else:\n",
    "            distances[i] = 1-dot(n_grams_counts, n_grams_source_counts)/(norm(n_grams_counts)*norm(n_grams_source_counts))\n",
    "\n",
    "\n",
    "    # Create an overview of the results including the original label and predicted label\n",
    "    results = pd.DataFrame(columns=[\"SourceAddress\",\"Cosine_Distance\",\"Label\",\"Prediction\"])\n",
    "\n",
    "    for i in range(len(distances)):\n",
    "        distance = distances[i]\n",
    "        source = unique_sources.SourceAddress.iloc[i]\n",
    "        infected = prof.is_infected(source, scenario)\n",
    "        normal = prof.is_normal(source)\n",
    "        label = -1\n",
    "\n",
    "        if infected == True:\n",
    "            label = 1\n",
    "        elif normal == True:\n",
    "            label = 0\n",
    "\n",
    "        results = results.append({\"SourceAddress\": source, \"Cosine_Distance\": distance, \"Label\": label, \"Prediction\": ''}, ignore_index=True)\n",
    "    \n",
    "    # For each threshold ranging from 0 to 0.25, in steps of 0.01 we check the results to be able to choose\n",
    "    # good threshold. This is only based on 'training' scenario 9, the other sets will use the threshold \n",
    "    # that has been chosen optimal in scenario 9\n",
    "    thresholds = np.arange(0,0.25,0.01)\n",
    "    for threshold in thresholds:\n",
    "        results.Prediction = results.Cosine_Distance.apply(lambda x: 1 if x <= threshold else 0)\n",
    "\n",
    "        TP, FP, FN, TN, new_infections, unknown = 0, 0, 0, 0, 0, 0\n",
    "\n",
    "        for i in range(len(results)):\n",
    "            row = results.iloc[i]\n",
    "            if row.Label == row.Prediction and row.Label == 1:\n",
    "                TP += 1\n",
    "            elif row.Label == 0 and row.Prediction == 1:\n",
    "                FP += 1\n",
    "            elif row.Label == 0 and row.Prediction == 0:\n",
    "                TN += 1\n",
    "            elif row.Label == 1 and row.Prediction == 0:\n",
    "                FN += 1\n",
    "                \n",
    "            # Number of unlabeled hosts\n",
    "            if row.Label == -1:\n",
    "                unknown += 1\n",
    "                \n",
    "            # Newly identified infected host\n",
    "            if row.Label == -1 and row.Prediction == 1:\n",
    "                new_infections += 1\n",
    "                \n",
    "        accuracy = (TP+TN)/(TP+FP+FN+TN)\n",
    "                \n",
    "        grid_search = grid_search.append({\"Scenario\": scenario, \"Threshold\": threshold, \"Unknown\": unknown, \"TP\": TP, \"FP\": FP, \"FN\": FN, \"TN\": TN, \"Accuracy\": accuracy,\"NEW_INFECTIONS\": new_infections}, ignore_index=True)\n",
    "\n",
    "# Uncheck print statement to see all results of results\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(grid_search)\n",
    "        \n",
    "# Manual evaluation of results of grid search delivered an optimal threshold of 0.18\n",
    "# For scenario 9 this threshold delivers 12 new infections at the cost of a couple false positives\n",
    "# For the other scenarios it didn't really matter which threshold to choose\n",
    "filter_threshold = grid_search.loc[grid_search.Threshold == 0.18]\n",
    "filter_threshold.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### Fingerprinting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 9\n",
      "147.32.84.165\n",
      "[ 4  5 10 11 12 15 19 20 21 24]\n",
      "TP: 5\n",
      "FP: 5\n",
      "TN: 0\n",
      "FN: 0\n",
      "NEW_INFECTIONS: 0\n",
      "acc: 0.5\n",
      "147.32.84.191\n",
      "[ 5  7 10 11 12 15 20 21 24]\n",
      "TP: 5\n",
      "FP: 5\n",
      "TN: 0\n",
      "FN: 0\n",
      "NEW_INFECTIONS: 0\n",
      "acc: 0.5\n",
      "147.32.84.192\n",
      "[]\n",
      "TP: 0\n",
      "FP: 0\n",
      "TN: 0\n",
      "FN: 0\n",
      "NEW_INFECTIONS: 0\n",
      "acc: nan\n",
      "147.32.84.193\n",
      "[]\n",
      "TP: 0\n",
      "FP: 0\n",
      "TN: 0\n",
      "FN: 0\n",
      "NEW_INFECTIONS: 0\n",
      "acc: nan\n",
      "147.32.84.204\n",
      "[]\n",
      "TP: 0\n",
      "FP: 0\n",
      "TN: 0\n",
      "FN: 0\n",
      "NEW_INFECTIONS: 0\n",
      "acc: nan\n",
      "147.32.84.205\n",
      "[20 24]\n",
      "TP: 4\n",
      "FP: 3\n",
      "TN: 0\n",
      "FN: 0\n",
      "NEW_INFECTIONS: 0\n",
      "acc: 0.5714285714285714\n",
      "147.32.84.206\n",
      "[ 4 10 21]\n",
      "TP: 4\n",
      "FP: 4\n",
      "TN: 0\n",
      "FN: 0\n",
      "NEW_INFECTIONS: 0\n",
      "acc: 0.5\n",
      "147.32.84.207\n",
      "[]\n",
      "TP: 0\n",
      "FP: 0\n",
      "TN: 0\n",
      "FN: 0\n",
      "NEW_INFECTIONS: 0\n",
      "acc: nan\n",
      "147.32.84.208\n",
      "[ 4 10 12 15 19 24]\n",
      "TP: 5\n",
      "FP: 3\n",
      "TN: 0\n",
      "FN: 0\n",
      "NEW_INFECTIONS: 0\n",
      "acc: 0.625\n",
      "147.32.84.209\n",
      "[]\n",
      "TP: 0\n",
      "FP: 0\n",
      "TN: 0\n",
      "FN: 0\n",
      "NEW_INFECTIONS: 0\n",
      "acc: nan\n",
      "Scenario 10\n",
      "147.32.84.165\n",
      "[ 9 21]\n",
      "TP: 2\n",
      "FP: 0\n",
      "TN: 0\n",
      "FN: 0\n",
      "NEW_INFECTIONS: 0\n",
      "acc: 1.0\n",
      "147.32.84.191\n",
      "[ 9 21]\n",
      "TP: 2\n",
      "FP: 0\n",
      "TN: 0\n",
      "FN: 0\n",
      "NEW_INFECTIONS: 0\n",
      "acc: 1.0\n",
      "147.32.84.192\n",
      "[]\n",
      "TP: 0\n",
      "FP: 0\n",
      "TN: 0\n",
      "FN: 0\n",
      "NEW_INFECTIONS: 0\n",
      "acc: nan\n",
      "147.32.84.193\n",
      "[]\n",
      "TP: 0\n",
      "FP: 0\n",
      "TN: 0\n",
      "FN: 0\n",
      "NEW_INFECTIONS: 0\n",
      "acc: nan\n",
      "147.32.84.204\n",
      "[]\n",
      "TP: 0\n",
      "FP: 0\n",
      "TN: 0\n",
      "FN: 0\n",
      "NEW_INFECTIONS: 0\n",
      "acc: nan\n",
      "147.32.84.205\n",
      "[]\n",
      "TP: 0\n",
      "FP: 0\n",
      "TN: 0\n",
      "FN: 0\n",
      "NEW_INFECTIONS: 0\n",
      "acc: nan\n",
      "147.32.84.206\n",
      "[]\n",
      "TP: 0\n",
      "FP: 0\n",
      "TN: 0\n",
      "FN: 0\n",
      "NEW_INFECTIONS: 0\n",
      "acc: nan\n",
      "147.32.84.207\n",
      "[]\n",
      "TP: 0\n",
      "FP: 0\n",
      "TN: 0\n",
      "FN: 0\n",
      "NEW_INFECTIONS: 0\n",
      "acc: nan\n",
      "147.32.84.208\n",
      "[]\n",
      "TP: 0\n",
      "FP: 0\n",
      "TN: 0\n",
      "FN: 0\n",
      "NEW_INFECTIONS: 0\n",
      "acc: nan\n",
      "147.32.84.209\n",
      "[]\n",
      "TP: 0\n",
      "FP: 0\n",
      "TN: 0\n",
      "FN: 0\n",
      "NEW_INFECTIONS: 0\n",
      "acc: nan\n",
      "Scenario 11\n",
      "147.32.84.165\n",
      "[7]\n",
      "TP: 1\n",
      "FP: 3\n",
      "TN: 0\n",
      "FN: 0\n",
      "NEW_INFECTIONS: 2\n",
      "acc: 0.25\n",
      "147.32.84.191\n",
      "[]\n",
      "TP: 0\n",
      "FP: 0\n",
      "TN: 0\n",
      "FN: 0\n",
      "NEW_INFECTIONS: 0\n",
      "acc: nan\n",
      "147.32.84.192\n",
      "[]\n",
      "TP: 0\n",
      "FP: 0\n",
      "TN: 0\n",
      "FN: 0\n",
      "NEW_INFECTIONS: 0\n",
      "acc: nan\n",
      "Scenario 12\n",
      "147.32.84.165\n",
      "[ 0  2  6  8 17 18 20 23 24 25]\n",
      "TP: 3\n",
      "FP: 3\n",
      "TN: 0\n",
      "FN: 0\n",
      "NEW_INFECTIONS: 0\n",
      "acc: 0.5\n",
      "147.32.84.191\n",
      "[17 23 25]\n",
      "TP: 3\n",
      "FP: 0\n",
      "TN: 0\n",
      "FN: 0\n",
      "NEW_INFECTIONS: 0\n",
      "acc: 1.0\n",
      "147.32.84.192\n",
      "[17 23 25]\n",
      "TP: 3\n",
      "FP: 0\n",
      "TN: 0\n",
      "FN: 0\n",
      "NEW_INFECTIONS: 0\n",
      "acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "from math import nan\n",
    "\n",
    "# For each scenario pick the infected host with the most unique n-gram.\n",
    "# Then check which n-gram does not occur in the non-infected host.\n",
    "# Pick top k n-grams that satisfy above criteria, check for other hosts\n",
    "\n",
    "scenarios = [9, 10, 11, 12]\n",
    "\n",
    "for scenario in scenarios:\n",
    "    print(\"Scenario \" + str(scenario))\n",
    "    if scenario == 9:\n",
    "        pdata = pdata9.copy()\n",
    "    elif scenario == 10:\n",
    "        pdata = pdata10.copy()\n",
    "    elif scenario == 11:\n",
    "        pdata = pdata11.copy()\n",
    "    elif scenario == 12:\n",
    "        pdata = pdata12.copy() \n",
    "\n",
    "    # Feature to use, including its optimal binsize, and discretized to be used for n-grams\n",
    "    feature = \"Protocol\"\n",
    "    nbins = 3\n",
    "\n",
    "    discretized_data = pd.DataFrame()\n",
    "    discretized_data[\"StartTime\"] = pdata[\"StartTime\"].copy()\n",
    "    discretized_data[\"SourceAddress\"] = pdata[\"SourceAddress\"].copy()\n",
    "    discretized_data[\"DestinationAddress\"] = pdata[\"DestinationAddress\"].copy()\n",
    "    pdata[\"Protocol\"] = prof.encode_feature(pdata[\"Protocol\"])\n",
    "    discretized_data[feature], binsedges_infected = prof.discretize_feature(pdata, feature, nbins, \"kmeans\")\n",
    "\n",
    "    # Select source with most entries in given dataset to deliver most reliable n-gram profile\n",
    "    selected_sources = prof.select_infected_host(pdata,scenario)\n",
    "    # ONLY FOR TEST LOOP OVER ALL INFECTED IPS     \n",
    "    for selected_source in selected_sources:\n",
    "        print(selected_source)\n",
    "        # selected_source = prof.select_infected_host(pdata,scenario)\n",
    "        filtered_source = discretized_data.loc[discretized_data.SourceAddress == selected_source]\n",
    "\n",
    "        ngram = 3\n",
    "        all_n_grams = list(itertools.product(*[['0','1','2'],['0','1','2'],['0','1','2']]))\n",
    "\n",
    "        n_grams = pd.Index(list(ngrams(filtered_source[feature].astype(str),ngram)))\n",
    "        n_grams_counts = [0]*len(all_n_grams)\n",
    "        for i in range(len(n_grams.value_counts())):\n",
    "            n_gram = n_grams.value_counts()\n",
    "            index_all_n_grams = all_n_grams.index(n_gram.index[i])\n",
    "            n_grams_counts[index_all_n_grams] = n_gram[i]\n",
    "\n",
    "        # Select all benign traffic(Non-infected)\n",
    "        non_infected_host = prof.select_non_infected_host(pdata)\n",
    "        unique_sources_benign = pd.DataFrame()\n",
    "        unique_sources_benign['SourceAddress'] = non_infected_host\n",
    "\n",
    "        # Sum all counts of all benign host(if n-gram == 0, does not occur in benign data)\n",
    "        sum_ngrams_benign = [0]*len(all_n_grams)\n",
    "        for i in range(len(unique_sources_benign)):\n",
    "            source = unique_sources_benign.iloc[i]\n",
    "\n",
    "            filtered = discretized_data.loc[discretized_data.SourceAddress == source.SourceAddress]\n",
    "            n_grams_source = pd.Index(list(ngrams(filtered[feature].astype(str),ngram)))\n",
    "            n_grams_source_counts = [0]*len(all_n_grams)\n",
    "\n",
    "            for j in range(len(n_grams_source.value_counts())):\n",
    "                n_gram = n_grams_source.value_counts()\n",
    "                index_all_n_grams = all_n_grams.index(n_gram.index[j])\n",
    "                n_grams_source_counts[index_all_n_grams] = n_gram[j]\n",
    "\n",
    "            # Check which n-gram does NOT occur in benign data\n",
    "            sum_ngrams_benign = np.add(sum_ngrams_benign, n_grams_source_counts)\n",
    "\n",
    "        # Pick all ngrams that does not occur in benign traffic     \n",
    "        n_grams_not_in_benign = np.array(sum_ngrams_benign)\n",
    "        n_grams_not_in_benign = np.where(sum_ngrams_benign == 0)[0]\n",
    "\n",
    "        # Pick all ngrams that occur in infected traffic     \n",
    "        n_grams_in_infected = np.array(n_grams_counts)\n",
    "        n_grams_in_infected = np.where(n_grams_in_infected > 0)[0]\n",
    "\n",
    "        # Pick the ngrams that does not occur in benign but occur in infected data     \n",
    "        possible_fingerprints = np.intersect1d(n_grams_in_infected, n_grams_not_in_benign)\n",
    "        print(possible_fingerprints)\n",
    "\n",
    "        ### PART 2 (CHECK WITH THE NGRAMS FIND ABOVE IF ANY (NEW) INFECTED HOSTS COULD BE DETECTED) ####    \n",
    "        # Group netflows by source address (host) because we are interested in modeling per-host behavior\n",
    "        unique_sources = pdata.groupby([\"SourceAddress\"]).size().reset_index()\n",
    "\n",
    "        # Check if fingerprint is contained in the data of the host\n",
    "        finger_print_exists = [100]*len(unique_sources)\n",
    "\n",
    "        for i in range(len(unique_sources)):\n",
    "            source = unique_sources.iloc[i]\n",
    "\n",
    "            filtered = discretized_data.loc[discretized_data.SourceAddress == source.SourceAddress]\n",
    "            n_grams_source = pd.Index(list(ngrams(filtered[feature].astype(str),ngram)))\n",
    "            n_grams_source_counts = [0]*len(all_n_grams)\n",
    "\n",
    "            for j in range(len(n_grams_source.value_counts())):\n",
    "                n_gram = n_grams_source.value_counts()\n",
    "                index_all_n_grams = all_n_grams.index(n_gram.index[j])\n",
    "                n_grams_source_counts[index_all_n_grams] = n_gram[j]\n",
    "\n",
    "            # Pick the indexes of the ngram that occur          \n",
    "            n_grams_in_source = np.array(n_grams_source_counts)\n",
    "            n_grams_in_source = np.where(n_grams_in_source > 0)[0]\n",
    "\n",
    "            # For each possible fingerprint check if it exists in the data\n",
    "            for fingerprint in possible_fingerprints:\n",
    "                # Raise alarm         \n",
    "                if fingerprint in n_grams_in_source:\n",
    "                    finger_print_exists[i] = 1\n",
    "\n",
    "        # # Create an overview of the results including the original label and predicted label\n",
    "        results = pd.DataFrame(columns=[\"SourceAddress\",\"Fingerprint_exists\",\"Label\",\"Prediction\"])\n",
    "\n",
    "        for i in range(len(finger_print_exists)):\n",
    "            finger_print = finger_print_exists[i]\n",
    "            source = unique_sources.SourceAddress.iloc[i]\n",
    "            infected = prof.is_infected(source, scenario)\n",
    "            normal = prof.is_normal(source)\n",
    "            label = -1\n",
    "\n",
    "            if infected == True:\n",
    "                label = 1\n",
    "            elif normal == True:\n",
    "                label = 0\n",
    "\n",
    "            results = results.append({\"SourceAddress\": source, \"Fingerprint_exists\": finger_print, \"Label\": label, \"Prediction\": finger_print}, ignore_index=True)\n",
    "        TP, FP, FN, TN, new_infections, unknown = 0, 0, 0, 0, 0, 0\n",
    "\n",
    "        for i in range(len(results)):\n",
    "            row = results.iloc[i]\n",
    "            if row.Label == row.Prediction and row.Label == 1:\n",
    "                TP += 1\n",
    "            elif row.Label == 0 and row.Prediction == 1:\n",
    "                FP += 1\n",
    "            elif row.Label == 0 and row.Prediction == 0:\n",
    "                TN += 1\n",
    "            elif row.Label == 1 and row.Prediction == 0:\n",
    "                FN += 1\n",
    "\n",
    "            # Number of unlabeled hosts\n",
    "            if row.Label == -1:\n",
    "                unknown += 1\n",
    "\n",
    "            # Newly identified infected host\n",
    "            if row.Label == -1 and row.Prediction == 1:\n",
    "                new_infections += 1\n",
    "        if (TP+FP+FN+TN) == 0:\n",
    "            accuracy = nan\n",
    "        else: accuracy = (TP+TN)/(TP+FP+FN+TN)\n",
    "        print(\"TP: \" + str(TP))\n",
    "        print(\"FP: \" + str(FP))\n",
    "        print(\"TN: \" + str(TN))\n",
    "        print(\"FN: \" + str(FN))\n",
    "        print(\"NEW_INFECTIONS: \" + str(new_infections))\n",
    "        print(\"acc: \" + str(accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The profiles found by the \"Botnet profiling task\" are here used to detect new infections by fingerprinting. For each scenario, the infected host with the most entries in the dataset is selected since this host has the most reliable n-gram profile. The n-gram(s) that only exists in the data of the infected host and not in the n-grams of all benign data is then used to detect possible new infected hosts.\n",
    "Above the results of the fingerprinting algorithm can be seen. ...\n",
    " \n",
    "Compared to the botnet profiling task, ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS4035 - Cyber Data Analytics\n",
    "## Lab 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit on brightspace (zip file with the name Group_xx.zip)\n",
    "(i) This jupyter file completed with code, plots, figures and report for each question. Additional plots and figures can be created for explanation before the end of each main question. Lab 2 contains 7 main questions, including the bonus. Write the code or explanation below each sub question. For the explantions, include what you would normally include in the report for this lab assignment, for example data pre-processing, hypothesis tested, approach, results, etc.\n",
    "(ii) A PDF or a Word report for the assignment. Create a report from the plots, figures, tables and the write-up that you provide in this jupyter file. The report will be used as a proof for page limit. \n",
    "(iii) The libraries needed to run this file. \n",
    "\n",
    "Your peers should be able to use the readme section for instructions and be able to run this file. \n",
    "\n",
    "Dataset here : https://www.batadal.net/data.html You will need Training Dataset 1, Training Dataset 1 and Test Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Number : 27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student 1 \n",
    "### Name : Joost Bambacht\n",
    "### ID : 4025016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student 2\n",
    "### Name : Lennart Overdevest\n",
    "### ID : 4374436"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readme - Provide instructions - libraries used, location of the data file, etc. Keep it short. Remember your peers will not debug your code and should be able to reproduce the exact output you provide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. pip3 install -r requirements.txt\n",
    "2. Run the code fragment for each task separately\n",
    "3. Some executions may take some time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Familiarization task â€“ 1 A4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Plot visualizations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Figure 1: types of signals in dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2200x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2200x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2200x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2200x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Figure 2: correlation between signals\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2500x2000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Figure 3: perfectly correlated signals\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2200x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2200x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Figure 4: perfectly negatively correlated signals\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2200x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2200x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Figure 5: prediction of the water tank signals\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2200x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2200x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2200x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2200x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2200x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2200x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2200x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE: 0.2850589383381013\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import familiarization as fam\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data = fam.load_data(\"data/BATADAL_dataset03.csv\")\n",
    "tdata = fam.pre_process(data)\n",
    "\n",
    "# Plot sample signals\n",
    "print(\"\\nFigure 1: types of signals in dataset\")\n",
    "fam.plot_signal(tdata,\"L_T1\",0,720,\"Water level of tank 1\",\"blue\")\n",
    "fam.plot_signal(tdata,\"F_PU1\",0,720,\"Flow through pump 1\",\"green\")\n",
    "fam.plot_signal(tdata,\"S_PU2\",0,720,\"Status of pump 2\",\"red\")\n",
    "fam.plot_signal(tdata,\"P_J280\",0,720,\"Pressure of joint 280\",\"black\")\n",
    "\n",
    "# Determine and plot correlation between signals\n",
    "print(\"\\nFigure 2: correlation between signals\")\n",
    "fam.plot_correlation(tdata)\n",
    "\n",
    "# Example of almost perfectly correlated signals\n",
    "print(\"\\nFigure 3: perfectly correlated signals\")\n",
    "fam.plot_signal(data,\"F_PU2\",0,720,\"Flow in pump 2\",\"blue\")\n",
    "fam.plot_signal(data,\"S_PU2\",0,720,\"Status of pump 2\",\"red\")\n",
    "\n",
    "# Example of almost perfectly negatively correlated signals\n",
    "print(\"\\nFigure 4: perfectly negatively correlated signals\")\n",
    "fam.plot_signal(data,\"F_PU1\",0,720,\"Flow in pump 1\",\"blue\")\n",
    "fam.plot_signal(data,\"F_PU2\",0,720,\"Flow in pump 2\",\"red\")\n",
    "\n",
    "# Example of almost perfectly negatively correlated signals\n",
    "print(\"\\nFigure 5: prediction of the water tank signals\")\n",
    "signals = [\"L_T1\", \"L_T2\", \"L_T3\", \"L_T4\", \"L_T5\", \"L_T6\", \"L_T7\"]\n",
    "rmse = list()\n",
    "for signal in signals:\n",
    "    rmse.append(fam.predict_signal(data,signal,0.9))\n",
    "print(\"Average RMSE:\",np.mean(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Answers to the three questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCADA is a system/network of software and hardware components in which the data from sensors and other industrial components like pumps and valves can be monitored and controlled from a centralized computer. These kind of systems are vunerable to cyber-physical attacks.\n",
    "\n",
    "The BATADAL dataset is a representation of (measured) data over time from tanks (7), pumps (11), valves (4, of which 1 actionable), and other hydraulic components like joints (12 in total) from the C-Town water distribution system. The information that is embedded in the dataset contains the water level in each tank, the flow through each pump and valve and their status at that time (0 for off, 1 for on), and the pressure in the joints. Each record additionally stored the date and hour, and the attack flag status (0 for no attack, 1 for attack, and -999 as unknown(?)).\n",
    "\n",
    "##### Signal types\n",
    "The signals that can be extracted from the dataset thus are the levels in the water tank, the flow through the pumps and valves, the status of each pump/valve over time, and the pressure in the joints. In Figure 1 all four signals can be seen over about a month in time for illustration purpose only. We can clearly see that the patterns for all signals are between boundaries, and look like to be repeating/cyclic in some form. We also see that the status indeed switches from off and on, although the value is only measured once every hour.\n",
    "\n",
    "##### Correlation\n",
    "To see if the signals are correlated we can determine the correlation between any columns in the dataset, and create a heatmap to easily visualize the correlation (see Figure 2). We see that most signals have a no correlation (value +-0), while there exist some perfect correlated signals (excluding the signals with theirselves) and perfect negatively correlated signals (signals move in opposite direction). For example the correlation of the flow of pump 2 (F_PU2) with the status of pump 2 (S_PU2) is 0.998614, meaning they are perfectly correlated. This is ofcourse not strange since if the pump is enabled (status code 1) the flow in the pump is also enabled, see Figure 3 for pattern comparison of a part of the signals. If we look at other signals (that are not from the same component), we see that for instance the flow in pump 1 is almost perfectly correlated with the pressure in joint 280, with a correlation value of 0.907052. This probably indicates that joint 280 is the connection leaving pump 2, while it is connected to something that is not flowing at the same speed as pump 2. We also see (Figure 4) that for instance the signals from F_PU1 and F_PU2 are perfectly negatively correlated with a value of -0.949012, meaning that when the signal from one of the two is going up or down, the other one is moving in the opposite direction. \n",
    "\n",
    "From the signals we can easily see that they look to be cyclic. From the flow in pump 2 signals in Figure 3 we see that in 24 hours (although it is measured ones per hour) the frequency of the signal repeating is about 14 times. The cycle is not a perfect sinusoidal, but the similarity between them is very well visible.\n",
    "\n",
    "###### Prediction\n",
    "For the prediction of the signals we use an AutoRegressive model that is trained by a training set, and for the prediction it takes previous observation(s) of the time series into account. The lag has been chosen to be closer to zero and not bigger since the more recent previous observations should be more important than extra previous observations (adding more lag decreases the influence of all other observations). In Figure 5 the original and predicted signals of the water tanks can be seen, including their RMSE. We can see that for all signals did well, although for signals L_T4, L_T5 and L_T7 the prediction is less accurate than for the others. If we compare signals L_T1 and L_T6, at first sight L_T1 looks like to be predicted better by a lot. If we look at the RMSE the difference is just a fraction.\n",
    "\n",
    "If instead of the water levels of the tanks we try to predict the signals of the flows of the 11 pumps, the result is very different. The average RMSE is increased to 7.59, and the predicted signal does not follow the curves of the original signal at all for most signals.\n",
    "\n",
    "Predicting the next value in a series thus differs if the signal is applicable for it. From what we've seen is that the water levels in the tanks are very fitting for prediction, while the flow in the pumps are not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LOF task â€“ 1/2 A4 â€“ Individual - Lennart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. Plot LOF scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import familiarization as fam\n",
    "import anomaly_detection as dtc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "data = fam.load_data(\"data/BATADAL_dataset03.csv\")\n",
    "test_data = fam.load_data(\"data/BATADAL_test_dataset.csv\")\n",
    "# Drop sequential context\n",
    "data = data.drop(['DATETIME'], axis = 1) \n",
    "lof_data = [ [] for _ in range(len(data['P_J306'])) ]\n",
    "\n",
    "# Define groups of signals\n",
    "LT_signals = ['L_T1', 'L_T2', 'L_T3', 'L_T4', 'L_T5', 'L_T6', 'L_T7']\n",
    "F_signals = ['F_PU1', 'F_PU2','F_PU3', 'F_PU4','F_PU5','F_PU6', 'F_PU7', 'F_PU8', 'F_PU9', 'F_PU10', 'F_PU11', 'F_V2']\n",
    "P_signals = ['P_J280',  'P_J289', 'P_J415', 'P_J302', 'P_J306',  'P_J422']\n",
    "\n",
    "# Define the maximial amount of nearest neighbours to use in the LOF method\n",
    "max_neighbours = 25\n",
    "# Compute and plot for each signal the LOF performance\n",
    "LT_lof = dtc.compute_lof(data, LT_signals, max_neighbours)\n",
    "dtc.plot_lof(LT_lof, LT_signals, max_neighbours, \"Influence of used numbers of neighbors in LOF - L_T signals\")\n",
    "\n",
    "F_lof = dtc.compute_lof(data, F_signals, max_neighbours)\n",
    "dtc.plot_lof(F_lof, F_signals, max_neighbours, \"Influence of used numbers of neighbors in LOF - F signals\")\n",
    "\n",
    "P_lof = dtc.compute_lof(data, P_signals, max_neighbours)\n",
    "dtc.plot_lof(P_lof, P_signals, max_neighbours, \"Influence of used numbers of neighbors in LOF - P signals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only used for clarification of the performance of the LOF \n",
    "sns.boxplot(data['F_PU6'], fliersize=3)\n",
    "plt.title(\"Boxplot of F_PU6 values\")\n",
    "plt.show()\n",
    "sns.boxplot(data['F_PU11'], fliersize=3)\n",
    "plt.title(\"Boxplot of F_PU11 values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find outliers of test data set using the amount of neighbours found by the code above\n",
    "test_signals = ['L_T1', 'L_T2', 'P_J302']\n",
    "\n",
    "LT_outliers = dtc.compute_lof(test_data, test_signals, 20, test=1)\n",
    "top_LT_outliers = []\n",
    "for i in range(len(LT_outliers)):\n",
    "    # Sort dictionary by values descending order aka find the most outliers \n",
    "    sorted_dict = sorted(LT_outliers[i], key=LT_outliers[i].get, reverse=True)\n",
    "    # Pick first 50 results and add to array     \n",
    "    top_LT_outliers.append(sorted_dict[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Analysis and answers to the questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the influence of the number of neighbors used in the algorithm on the detection of anomalies,\n",
    "the number of neighbors is plotted as a function of the number of anomalies detected. This is done for each type of signal(L_T, F, P). The amount of neighbors used, is chosen from 1 till 25. The upper bound is chosen because in the documentation of the SK-Learn package it is stated that \"20 neighbors appears to work well in general\". To see if the performance could be increased when using a larger value than 20, the upper bound is set to 25. Another variable that has an impact on the performance of LOF is the threshold used to decide whether a data point is an anomaly. Several threshold values are tested and -1.5 was chosen as the final threshold value.\n",
    "From the plots above it can be seen that indeed the upper bound of the number of neighbors used could be set to 20 since the number of anomalies detected does not change much after this. An even smaller number of neighbors, approximately 16, could be used for the F and P signal types because they already converged at that point.\n",
    "\n",
    "Remarkable are the F_P06 and the F_PU11 signals because they follow a different pattern as can be seen in the second plot. If we look at the data points of these two signals in figure 4 and 5, the behavior could relatively easily be explained. As can be seen in the bottom boxplot, the  it consists of four points with a value close to each other and all other points have a value close to zero. In the figure 2 it can be seen that when 3 or less neighbors are used, these points are not seen as outliers because they form a cluster by themself. However, when a higher amount of neighbors is used these are classified as outliers because it uses the distance of a data point with value zero. This results in detecting the four points as outliers.\n",
    "Approximately, the same reasoning could be used for the behavior of the L_PU6 line. Although, the number of neighbors to reach the detection of the outliers is 16.\n",
    "\n",
    "Concluded could be that a 20 is a suitable value for the amount of neighbors. Since all signals are converged to a stable solution. This value is of course depends on the threshold value which decides whether a point is an anomaly.\n",
    "Anomalies in signals could occur when, for example, hardware is not stable. It is very important to know the context around the type of signal. Take F_PU11, as an example, 0.04%(4/8761) of the measured values differ a lot compared to the other 99.96%. Without knowing the context of the type of signal these values would be classified as anomalies. However, knowing that this is the flow through the pump, it could easily be reasoned that the pump is only used very few times.\n",
    "\n",
    "LOF measures the local deviation of a given point with respect to its neighbours, therefore LOF is a suitable method to detect anomalies in signals, since signals most of the time repeat after some time. However, it is very important to find the optimal value for k. Fortunately, there are many techniques to find the optimal value for k.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PCA task â€“ 1/2 A4 â€“ Individual - Joost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Plot PCA residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%reset -f\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pca_helper as pca_helper\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "data = pca_helper.load_data(\"data/BATADAL_dataset03.csv\")\n",
    "tdata, labels = pca_helper.pre_process(data)\n",
    "\n",
    "data2 = pca_helper.load_data(\"data/BATADAL_dataset04.csv\")\n",
    "tdata2, labels2 = pca_helper.pre_process(data2,True)\n",
    "\n",
    "# Create residual plots for different number of components, starting from 95% and ending at 99%\n",
    "variances = [0.95, 0.96, 0.97, 0.98, 0.99]\n",
    "pca = list()\n",
    "components = list()\n",
    "x = list()\n",
    "x_fitted = list()\n",
    "error = list()\n",
    "mean_data = list()\n",
    "std_data = list()\n",
    "\n",
    "for var in variances:\n",
    "    pca.append(PCA(n_components=var, random_state=33))\n",
    "\n",
    "for p in pca:\n",
    "    index = pca.index(p)\n",
    "    x.append(p.fit_transform(tdata))\n",
    "    components.append(p.components_)\n",
    "    \n",
    "    x_fitted.append(np.matmul(x[index],components[index]))\n",
    "    \n",
    "    error.append(np.sum((tdata-x_fitted[index])**2,axis=1))\n",
    "    \n",
    "    plt.subplots(figsize=(15,3))\n",
    "    plt.title('PCA Residual including '+str(variances[index])+' of total variance / '+str(len(components[index]))+' components')\n",
    "    plt.plot(error[index])\n",
    "    plt.show()\n",
    "    print(\"Total error of all components for variance \"+str(variances[index])+\": \",np.sum(error))\n",
    "print(\"Figure 3.1: Residual plots for variance levels 0.95 to 0.99\")\n",
    "\n",
    "# Plot the number of components and its value to the total variance\n",
    "n_features = len(tdata.columns)\n",
    "pca_all = PCA(n_components=n_features, random_state=33)\n",
    "pca_all.fit_transform(tdata)\n",
    "\n",
    "pca_helper.number_of_components_plot(pca_all, len(tdata.columns), 0.97);\n",
    "print(\"Figure 3.2: Number of components at variance level 0.97\")\n",
    "\n",
    "# Detect and remove outliers from dataset\n",
    "mean = list()\n",
    "std = list()\n",
    "outliers = set()\n",
    "columns = tdata.columns\n",
    "\n",
    "# For each signal we separately determine the mean and standard deviation,  \n",
    "# such that outliers can be detected for each signal.\n",
    "for col in columns:\n",
    "    mean.append(np.mean(tdata[col]))\n",
    "    std.append(np.std(tdata[col]))\n",
    "    \n",
    "for i in range(len(tdata)):\n",
    "    row = tdata.loc[i]\n",
    "    \n",
    "    for j in range(len(columns)):\n",
    "        if row[columns[j]] < mean[j]-3*std[j] or row[columns[j]] > mean[j]+3*std[j]:\n",
    "            outliers.add(i)\n",
    "            \n",
    "tdata_without_outliers = tdata.copy()\n",
    "tdata_without_outliers.drop(outliers, inplace=True)\n",
    "\n",
    "# Create new residual plots, without the anomalies\n",
    "pca_new = PCA(n_components=0.97, random_state=33)\n",
    "x_new = pca_new.fit_transform(tdata_without_outliers)\n",
    "components_new = pca_new.components_\n",
    "x_fitted_new = np.matmul(x_new,components_new)\n",
    "error_new = np.sum((tdata_without_outliers-x_fitted_new)**2,axis=1)\n",
    "\n",
    "f,ax = plt.subplots(figsize=(15,3))\n",
    "plt.title('PCA Residual including 0.97 of total variance / 13 components after outlier removal')\n",
    "plt.plot(error_new)\n",
    "plt.show()\n",
    "print(\"Outliers detected and removed: \",len(outliers))\n",
    "print(\"Figure 3.3: Residual plot for variance level 0.97 after anomaly removal\")\n",
    "\n",
    "# Create plot comparison of original dataset vs the removal of outliers\n",
    "f, ax = plt.subplots(figsize=(20,5))\n",
    "ax.plot(tdata, color='green');\n",
    "ax.plot(tdata_without_outliers, color='red');\n",
    "\n",
    "label_original = matplotlib.patches.Patch(color='green', label='Original Dataset')\n",
    "label_without_outliers = matplotlib.patches.Patch(color='red', label='Original Dataset without Outliers')\n",
    "plt.legend(loc='upper right', handles=[label_original, label_without_outliers]);\n",
    "plt.title(\"Comparison between original dataset and dataset with outliers removed\");\n",
    "plt.show()\n",
    "print(\"Figure 3.4: Comparison of original dataset and after anomaly removal\")\n",
    "\n",
    "# Apply the trained model from the first dataset to the second training dataset.\n",
    "# For this dataset the actual attacks are known, and can thus be used verify results.\n",
    "# Compute the (normalized) residual\n",
    "transformed_data = pd.DataFrame(pca_new.transform(tdata2), tdata2.index)\n",
    "inverse_data = pd.DataFrame(pca_new.inverse_transform(transformed_data), transformed_data.index, columns=tdata2.columns)\n",
    "residual = np.abs(np.sum(tdata2-inverse_data,axis=1))\n",
    "residual = residual/max(residual)\n",
    "\n",
    "# Find the optimal threshold by plotting all elements.\n",
    "# We want a high number of TP correspondig with a low FP => high precision\n",
    "# Pre-calculated optimum at index 448, or 0.5010854719373081 in value\n",
    "plot_metric_results = False\n",
    "if plot_metric_results == True:\n",
    "    pca_helper.plot_threshold_search(residual, labels2)\n",
    "\n",
    "# Predict labels for threshold\n",
    "threshold = 0.5010854719373081\n",
    "labels_pred = pca_helper.predict_labels(residual,threshold)\n",
    "    \n",
    "# Plot the result with the computed threshold\n",
    "f,ax = plt.subplots(figsize=(22,4))\n",
    "plt.plot(residual, label='Residual', color='blue')\n",
    "plt.plot(labels2,label='Attack Interval', color='yellow')\n",
    "plt.axhline(threshold, color='green', label='Threshold')\n",
    "ax.set_title(\"Residual plot vs attacks in training set 2, based on model training set 1\",size=14)\n",
    "ax.set_ylabel(\"Normalized residual error\",size=12)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "print(\"Figure 3.5: Residual plot of anomaly detection on training set 2\")\n",
    "\n",
    "# Evaluate the performance of the anomaly detection\n",
    "pca_helper.performance(labels2,labels_pred)\n",
    "\n",
    "\n",
    "# Plot different types of anomalies detected in residual plot\n",
    "pca_helper.plot_anomaly_range(residual, 60,85,'point');\n",
    "pca_helper.plot_anomaly_range(residual, 1700,1800,'collective')\n",
    "print(\"Figure 3.6: Types of anomalies detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Analysis and answers to the questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can apply PCA we must normalize the training dataset 1. Since PCA is affected by scale the features must be scaled before it can be applied to it. To obtain optimal performance in machine learning algorithms it requires the features of the dataset to be unit scale, with zero mean and variance one. We remove features that contains NaN values. The remaining 36 features can be used for PCA decomposition. For PCA to work with anomaly detection it must lower the number of components because otherwise it has a difficult time differentiating anomalies from normal cases. The cumulative variance of the principal components (n) determines the number of components for a defined threshold. To be able to detect the normal behaviour of the series, enough variance must still be present. However, too much variance can mean that the model has learned about the anomalies as well. \n",
    "\n",
    "In Figure 3.1 the PCA residuals of all signals with the corresponding number of components can be seen. It looks like that 99% removes too much anomalies, while for lower than 97% it is hard to distinquish what is an anomaly and what not. The total error increases a lot if the variance is increased. We therefore choose to use a cumulative variance of 97%, containing only 13 components. In Figure 3.2 the number of components is displayed against the cumulative variance. The last 21 components add a lot of error to the residuals, and are considered to be of less use.\n",
    "\n",
    "The next step is to remove anomalies from the dataset. To remove the outliers we have to set a threshold. We assume a normal distribution. The threshold for normal behaviour samples is estimated to be mean plus/minus three times the standard deviation [1] for each signal separately in the original dataset (after processing). For this interval there are 85 anomalies detected and removed. Some large anomalies are present in the dataset, see Figure 3.4. All signals now behave in somewhat the same boundaries. The model should be trained after these anomalies are removed as much as possible, otherwise the model also learnes information about the anomalies thinking it is normal data. In some situations it may occur that the values of the sensors in the SCADA system do not follow the correct patterns due to for instance an operator that is evaluating a problem, a broken sensor, or a software bug.\n",
    "\n",
    "The performance of the PCA-based anomaly detection can be evaluated by applying training set 2 to the trained model. We search for a suited threshold on the residual error, in which most attacks can be recognized by just looking at the residuals. The threshold is found by optmizing the precision (maximizing TP and minimizing FP). Training set 2 contains attack labels, such that we can easily evaluate the performance. In Figure 3.5 the residual plot of training set with the calculated threshold is visualized, in combination with the attack labels. It has an accuracy of 91% and a precision of about 96%. There are only 5 false positives, compared to the 123 true positives, which shows good performance for the anomaly detection.\n",
    "\n",
    "We can also look at the anomaly detections in detail in Figure 3.6, in which a couple of situations are visualised. The first plot indicates a point anomaly and the second one a collective anomaly. There is no contextual anomaly detected.\n",
    "\n",
    "[1] VARUN CHANDOLA, ARINDAM BANERJEE, and VIPIN KUMAR. Anomaly Detection: A Survey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ARMA task â€“ 1/2 A4 - Individual - Joost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a. Print relevant plots and/or metrics to determine the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%reset -f\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import arma_helper\n",
    "\n",
    "data_train = arma_helper.load_data(\"data/BATADAL_dataset03.csv\")\n",
    "train_data, train_labels = arma_helper.pre_process(data_train)\n",
    "data_test = arma_helper.load_data(\"data/BATADAL_test_dataset.csv\")\n",
    "test_data, test_labels = arma_helper.pre_process(data_test, test=True)\n",
    "sensors = [\"L_T1\",\"L_T2\",\"L_T3\",\"L_T4\",\"L_T5\",\"L_T6\",\"L_T7\"]\n",
    "\n",
    "## Plot autocorrelation plots and partial autocorrelation plots for the sensors mentioned above\n",
    "for sensor in sensors:\n",
    "    arma_helper.plot_autocorrelation(train_data[sensor], sensor)\n",
    "    \n",
    "# Calculate or take pre-calculated orders for signals\n",
    "p, q = arma_helper.compute_parameters(False, train_data, sensors, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b. Plots to study the detected anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%reset -f\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import arma_helper\n",
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning, ValueWarning, HessianInversionWarning\n",
    "warnings.simplefilter('ignore', ConvergenceWarning)\n",
    "warnings.simplefilter('ignore', ValueWarning)\n",
    "warnings.simplefilter('ignore', HessianInversionWarning)\n",
    "\n",
    "data_train = arma_helper.load_data(\"data/BATADAL_dataset03.csv\")\n",
    "train_data, train_labels = arma_helper.pre_process(data_train)\n",
    "data_test = arma_helper.load_data(\"data/BATADAL_test_dataset.csv\")\n",
    "test_data, test_labels = arma_helper.pre_process(data_test, test=True)\n",
    "\n",
    "sensors = [\"L_T1\",\"L_T2\",\"L_T3\",\"L_T4\",\"L_T5\",\"L_T6\",\"L_T7\"]\n",
    "p, q = arma_helper.compute_parameters(False, train_data, sensors, True)\n",
    "\n",
    "# For each sensor we first train the model, based on the parameters calculated before, and for all elements in the\n",
    "# test set we predict the next value based on previous point, and equations of AR and MA.\n",
    "test_sets = list()\n",
    "prediction_sets = list()\n",
    "for sensor in sensors:\n",
    "    index = sensors.index(sensor)\n",
    "    predictions = arma_helper.predict_signal(sensor, train_data[sensor],test_data[sensor], p[index], q[index], False)\n",
    "    prediction_sets.append(predictions)\n",
    "    test_sets.append(test_data[sensor])\n",
    "    \n",
    "# For each sensor we determine the residual, threshold, anomalies and plot them for visualization\n",
    "for sensor in sensors:\n",
    "    index = sensors.index(sensor)\n",
    "    arma_helper.plot_residual_anomalies(test_sets[index], prediction_sets[index], test_labels, sensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4c. Analysis and answers to the questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can apply ARMA to the signals of the sensors we have to pre process them. We remove the columns that are not interesting for finding anomalies: binary values, mean zero, variance zero. We could also determine whether the signals of the sensor we will use are stationary, but since ARIMA (instead of ARMA) can deal with stationary, we will not research this. We first have to figure out the order of the ARMA models, by applying the Akaike's Information Criterion in a grid search to figure out which parameters suit the model best given the training data. We can also look at the autocorrelation and partial autocorrelation plots to verify the numbers.\n",
    "\n",
    "The only sensors in the SCADA system are the ones measuring the water levels in the tanks (tank 1 to 7). For each of the 7 sensors we are going to train the model, using the computed parameters p and q, based on the training data 1, and predict the data based on the test data. The test data contains attack flags, which we can use to evaluate the performance. The residual error is computed by taking the absolute values of the difference between the values of the test set and the predicted values. The anomalies are then the values that are bigger than a defined threshold. The threshold is estimated to be equal to the mean plus three times the standard deviation of the residual error, which in total includes 99.7% of the points to be 'normal'. We plotted the figures containing the predicted anomalies, residual error, threshold and true attacks in one figure for each sensor to show the result. The metrics are also given for each sensor. We see that the overall accuracy is quite well, although the precision and recall aren't that well. The anomalies that are detected are point anomalies and collective anomalies. These types are suitable for the threshold-based detection. If we look at the results of the anomalie detection of each sensor, we can clearly see that most are not suitable to be modeled using ARMA. There are two sensors that look like to perform relatively fine compared to the others: L_T2 and L_T3. In most cases there are more FalsePositives than TruePositives, and a lot of FalseNegatives and TrueNegatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. N-gram task â€“ 1/2 A4 - Individual - Lennart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5a. Visualise discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import Ngram as ng\n",
    "import familiarization as fam\n",
    "\n",
    "# Load the data  \n",
    "signal_train = fam.load_data(\"data/BATADAL_dataset03.csv\")\n",
    "signal_test = fam.load_data(\"data/BATADAL_test_dataset.csv\")\n",
    "discrite_size = 5\n",
    "# To increase the runtime one signal is taken\n",
    "signals = ['L_T1'] #  'L_T1', 'P_J280', 'F_PU3']\n",
    "for signal in signals: \n",
    "    # Discretize data      \n",
    "    dicretize_train, bins = ng.dicretize_data(signal_train, signal, discrite_size)\n",
    "    dicretize_test, bins = ng.dicretize_data(signal_test, signal, discrite_size)\n",
    "\n",
    "    # Plot the selected signal for both the training and test set \n",
    "    ng.plot_discretize(dicretize_train, signal, discrite_size, bins, 'train')\n",
    "    ng.plot_discretize(dicretize_test, signal, discrite_size, bins, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# Intialize hyperparameters\n",
    "n = 10\n",
    "stepsize = 5\n",
    "sliding_windows = [30, 50, 100, 200, 400]\n",
    "\n",
    "# Compute the matrix where the row represents the size of the sliding windows and the columns the N-grams.\n",
    "# The cells in the matrix represent the occurence of the N-gram in that sliding window\n",
    "train_matrices = {}\n",
    "test_matrices = {}\n",
    "# For simplicity and to avoid enormous runtime, it is only done for signal\n",
    "# for signal in signals:\n",
    "print(signal)\n",
    "train_ngram_matrix = ng.compute_ngram_matrix(signal_train, dicretize_train, signal, sliding_windows, n, stepsize)\n",
    "train_matrices[signal] = train_ngram_matrix\n",
    "\n",
    "test_ngram_matrix = ng.compute_ngram_matrix(signal_test, dicretize_test, signal, sliding_windows, n, stepsize)\n",
    "test_matrices[signal] = test_ngram_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "from numpy import dot\n",
    "import itertools\n",
    "# Threshold to which top the new instances are compared\n",
    "L_threshold = 50\n",
    "\n",
    "# For each signal compute similarities\n",
    "for signal in signals:\n",
    "    # Dictonary where key is the n-gram and value the closest distance\n",
    "    # to a n-gram from the top X n-grams of the training data     \n",
    "    best_matches = {}\n",
    "    # Get top L n-grams(which occurs the most in the training data)     \n",
    "    top_L = ng.get_most_freq_ngrams(train_matrices[signal], L_threshold)\n",
    "    test_ngram_marix = test_matrices[signal]\n",
    "    # Compute similarity using frequencies and check to which top L class it belongs\n",
    "    for ngram in test_ngram_matrix.columns:\n",
    "        # Set max distance         \n",
    "        min_distance = 1\n",
    "        # Get frequencies of test n-gram         \n",
    "        ngram_test = test_ngram_matrix.loc[:,ngram]\n",
    "        # Find n-gram that is closest to new instance         \n",
    "        for top_ngram in top_L:\n",
    "            # Get frequencies             \n",
    "            cur_top_ngram = train_matrices[signal].loc[:,top_ngram]\n",
    "            # compute cosine distance \n",
    "            cos_sim = dot(ngram_test, cur_top_ngram) / (norm(ngram_test)*norm(cur_top_ngram))\n",
    "            cos_distance = 1 - cos_sim\n",
    "            # Save smallest distance              \n",
    "            if cos_distance < min_distance:\n",
    "                min_distance = cos_distance\n",
    "                best_match = top_ngram               \n",
    "        best_matches[ngram] = min_distance\n",
    "    # Sort on distance (descending)         \n",
    "    test_n_gram_similarities = {k: v for k, v in sorted(best_matches.items(), key=lambda item: item[1], reverse=True)}\n",
    "    # Print top 25 most not matching n-gram     \n",
    "    top_n_grams_not_similiar = list(itertools.islice(test_n_gram_similarities.items(), 0, 25))\n",
    "    print(top_n_grams_not_similiar)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5b. Analysis and answers to the questions. Also provide relevant plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To show results of different signals, I precomputed the cosine distances of the ngrams to avoid long runtime\n",
    "res_L_T1 = [('4333444443', 0.1471308100400862), ('3444443332', 0.11791797571175144), ('3223333334', 0.03248964419254374), ('3333443334', 0.02030882086644259), ('2333333433', 0.020083775493427547), ('3443334444', 0.017604730357909326), ('2233333343', 0.015781603085244567), ('3333334333', 0.01331778285802998), ('3334433344', 0.011531782011276914), ('3344333444', 0.011531782011276914), ('4333333223', 0.0071478302743757105), ('3333332233', 0.006246682529413294), ('3322333333', 0.006246682529413294), ('4444433344', 0.005531917936978825), ('4444333444', 0.005531917936978825), ('4433344444', 0.005086782726468231), ('2233333443', 0.004896077792546971), ('2333334433', 0.004896077792546971), ('4443333332', 0.004663928486063895), ('4433333322', 0.004663928486063895), ('3333322333', 0.004122720955661352), ('3333223333', 0.004122720955661352), ('3332233333', 0.004122720955661352), ('3343333332', 0.0038263089936959593), ('4443334444', 0.003685347089432689)]\n",
    "res_P_J302 = [('2343344322', 0.2222671286730108), ('3433443222', 0.2222671286730108), ('4334432222', 0.2222671286730108), ('3344322223', 0.2222671286730108), ('3443222233', 0.2222671286730108), ('4432222333', 0.2222671286730108), ('4322223332', 0.2222671286730108), ('3222233323', 0.2222671286730108), ('2222333232', 0.2222671286730108), ('2223332322', 0.2222671286730108), ('2322444423', 0.2222671286730108), ('3224444232', 0.2222671286730108), ('2244442322', 0.2222671286730108), ('2444423224', 0.2222671286730108), ('4444232245', 0.2222671286730108), ('2222444424', 0.2222671286730108), ('4244344444', 0.2222671286730108), ('2443444442', 0.2222671286730108), ('4434444422', 0.2222671286730108), ('4344444222', 0.2222671286730108), ('4422223334', 0.2222671286730108), ('4222233342', 0.2222671286730108), ('2233323224', 0.22226712867301068), ('2333232244', 0.22226712867301068), ('3332322444', 0.22226712867301068)]\n",
    "res_P_J280 =  [('3333133133', 0.23705910047690215), ('3331331333', 0.23705910047690215), ('3313313333', 0.23705910047690215), ('3133133333', 0.23705910047690215), ('1331333333', 0.23705910047690204), ('1111113133', 0.159133666459354), ('1111131333', 0.15187545030145289), ('1131111113', 0.13611527588786065), ('1311111131', 0.13611527588786065), ('3111111313', 0.13611527588786065), ('6111111131', 0.12227281754440678), ('1111111311', 0.12227281754440678), ('1111113111', 0.12227281754440678), ('3313111333', 0.06333606035085959), ('1333333131', 0.058976102596134505), ('3131113333', 0.05614617979784986), ('1311133333', 0.05614617979784986), ('3333131113', 0.051699735731830954), ('3331311133', 0.051699735731830954), ('1133333113', 0.03260573214869389), ('1333331131', 0.024664775669302585), ('3113133333', 0.02293901306657875), ('6611111113', 0.015575464714775111), ('6111111333', 0.015182040916329465), ('1131333333', 0.014212305908801404)]\n",
    "res_F_PU1 = [('4455544444', 0.15952253990168852), ('4555444444', 0.15227393623589136), ('5544445554', 0.13650050522921764), ('5444455544', 0.13650050522921764), ('4444555444', 0.13650050522921764), ('4445554444', 0.13650050522921764), ('5544445455', 0.01647318247583862), ('5545555444', 0.015347803059002185), ('5554444555', 0.015304247612172417), ('5444454555', 0.013729964685061269), ('4444545555', 0.013729964685061269), ('4445455555', 0.013729964685061269), ('5455554444', 0.012638655808849708), ('4555544445', 0.012638655808849708), ('5555444454', 0.012638655808849708), ('5554444545', 0.012638655808849708), ('5555455554', 0.011601079247975932), ('5554555544', 0.011601079247975932), ('5555544445', 0.009078715372996093), ('5555444455', 0.009078715372996093), ('5555545555', 0.003072336288781563), ('5554444445', 0.0025601307254018435), ('5544444455', 0.0025601307254018435), ('5444444555', 0.0025601307254018435), ('4444555544', 0.0025601307254018435)]\n",
    "res_L_T2 = [('1122334555', 0.21115519081006884), ('1111223345', 0.2050442782046007), ('1112233455', 0.2050442782046007), ('3455555444', 0.18929805953872259), ('1223345555', 0.1805735463689856), ('2334555554', 0.1805735463689856), ('5554444445', 0.1587100210526502), ('4555444444', 0.1503548182328912), ('5444444455', 0.14754273031977283), ('3334445554', 0.14754273031977283), ('4455544444', 0.13825237030997017), ('5544444445', 0.13825237030997017), ('3444555444', 0.13825237030997017), ('3344433344', 0.13455458301842238), ('3444333444', 0.12408743616179041), ('4443334445', 0.12408743616179041), ('4433344455', 0.12408743616179041), ('4333444555', 0.12408743616179041), ('3211122233', 0.11255454267775644), ('3333444333', 0.11174052131984269), ('3334443334', 0.11174052131984269), ('2223333344', 0.10340419414142121), ('5444321112', 0.10109106456093697), ('4443211122', 0.10109106456093697), ('4432111222', 0.10109106456093697)]\n",
    "\n",
    "# Print precomputed results\n",
    "print('\\033[1m' + \"Top 25 n-grams with highest cosine distance\" + '\\033[0m')\n",
    "print(\"L_T1\")\n",
    "print(res_L_T1)\n",
    "print(\"P_J302\")\n",
    "print(res_P_J302)\n",
    "print(\"P_J280\")\n",
    "print(res_P_J280)\n",
    "print(\"F_PU1\")\n",
    "print(res_F_PU1)\n",
    "\n",
    "# Create dicretized signal\n",
    "signals = ['L_T1', 'L_T2', 'P_J302']\n",
    "signal_tot = []\n",
    "\n",
    "# Discretize data for each signal\n",
    "dicretize_test_L_T1, bins = ng.dicretize_data(signal_test, 'L_T1', discrite_size)\n",
    "dicretize_test_L_T2, bins = ng.dicretize_data(signal_test,'L_T2', discrite_size)\n",
    "dicretize_test_P_J302, bins = ng.dicretize_data(signal_test, 'P_J302', discrite_size)\n",
    "\n",
    "# Save dicretized data in array\n",
    "discretized_data = [dicretize_test_L_T1, dicretize_test_L_T2, dicretize_test_P_J302]\n",
    "string_res = []\n",
    "\n",
    "# Create signal string containing the discretized data \n",
    "for disc_data in discretized_data:\n",
    "    string = ''\n",
    "    for i in disc_data:\n",
    "        string +=  str(i)\n",
    "    string_res.append(string)\n",
    "# Save the cosine distances of the different signals \n",
    "results = [res_L_T1, res_L_T2, res_P_J302]\n",
    "\n",
    "count = 0\n",
    "plot_data = []\n",
    "\n",
    "# Find the ngram indexes in the test signal\n",
    "for result in results:\n",
    "    match_ngrams = []\n",
    "    for tup in result:\n",
    "        found_indexes = [i for i in range(len(string_res[count])) if string_res[count].startswith(tup[0], i)]\n",
    "        for i in found_indexes:\n",
    "            match_ngrams.append(i + n - 1)\n",
    "    indexes_of_signal = sorted(set(match_ngrams))\n",
    "    plot_data.append(indexes_of_signal)\n",
    "    count += 1\n",
    "\n",
    "# Define range to plot, dependent on the indexes of the anomalies\n",
    "ng.plot_anomaly(signal_test, 'L_T1', plot_data[0], 0, 500)\n",
    "ng.plot_anomaly(signal_test, 'L_T2', plot_data[1], 0, 500)\n",
    "ng.plot_anomaly(signal_test, 'P_J302', plot_data[2], 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first figure the result of the discretization of the L_T1 signal can be seen. The L_T1 signal is chosen because the values in this signal differ much and therefore it is a challenge to detect anomalies. If, for example, a binary signal was chosen it would be very easy to detect anomalies.\n",
    "Each value in the signal is categorized into one of the five bins. The ranges of the bins are defined by looking at the difference between the minimum and maximum value of the signal, the difference is then divided by five to have bins with an equal range window. I have chosen for five bins to simplify the pattern of the signal as much as possible.\n",
    "From the figure we can conclude that the data is evenly distributed among the different bins. Remarkable, is that the test set have almost none data points categorized in the last category.\n",
    "\n",
    "After the data has been discretized, N-grams are applied to several sliding windows. An matrix is created where the rows represent the different used sizes for the sliding windows and the columns represent the n-grams. Then each cell is filled with the normalized frequency of the n-grams in the different sliding windows. The sliding windows used are 30, 50, 100, 200, 400. These values are chosen to check what kind of influence the length of the sliding window has on the performance. A value of 10 is chosen for n. If n is too small it would be hard to see the relation between the data points. The step size is set to 5, this is mainly done to increase the runtime of the algorithm. This value is used to shift the sliding windows in time. When a step size of 1 is used it would take very long to create the n-gram matrix. The last parameter, L, is set to 50. This values takes the top 50 most frequent n-grams found in the training data. The n-grams in the test data are compared to these top L to classify the n-grams of the test data.\n",
    "The above defined hyperparameters are chosen based on intuition and by looking at the data/figures. To increase the performance of the algorithm, hyperparameter tuning need to be done. However, because of limited time I was not able to do this thorough.\n",
    "\n",
    "The results of 5 different signals are printed. For each signal, the top 25 n-grams that have the highest cosine distance compared to the top L n-grams of the training set are shown. \n",
    "Remarkable, it can be seen that the distances differ a lot and also highly depend on the type of signal.\n",
    "In the last plots, the anomalies detected for signal L_T1 and L_T2 are plotted for a specified range. This is done by translating the n-grams back to the original data points. So, the n-gram is looked up in the discretized signal. When the index is found we need to get the point which marks this n-gram as an anomaly. This is done by adding (n-1) to the found index. \n",
    "\n",
    "In the plots it can be seen that the anomalies are most of the time detected when the signal was expected to go up or down but does the opposite. From the figures we can conclude that the anomalies detected for L_T are more explainable than the anomalies detected for the P_J signal. Look, for example, at the plot of signal P_J302, it is hard to explain why these points are classified as anomalies. However, this could also be the reason of the chosen hyperparameters. So, as mentioned earlier, to increase the performance of the algorithm, the chosen hyperparameters need to be optimized per signal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.Comparision task 1 A4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6a. Use the given guidelines and provide a comparision of the above implemented methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The comparison task involves comparing the four methods used in the previous tasks. However, the implementations of the two authors deviate too much to be able to make a good comparison. Therefore, we decided to compare the the PCA and ARMA methods, and the LOF and NGRAM methods against each other. This way we can still make a comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import comparison as comp\n",
    "\n",
    "# Calculate anomalous regions  \n",
    "res_anomalous_regions_pca, labels_true_pca, labels_pred_pca = comp.get_anomalous_regions(\"pca\",False)\n",
    "res_anomalous_regions_arma, labels_true_arma, labels_pred_arma = comp.get_anomalous_regions(\"arma\",False)\n",
    "print(\"Anomalous Regions PCA:\",res_anomalous_regions_pca, \"SUM:\",np.sum(res_anomalous_regions_pca), \"AVERAGE:\", np.mean(res_anomalous_regions_pca))\n",
    "print(\"Anomalous Regions ARMA:\",res_anomalous_regions_arma, \"SUM:\",np.sum(res_anomalous_regions_arma), \"AVERAGE:\", np.mean(res_anomalous_regions_arma))\n",
    "\n",
    "# Performances\n",
    "accuracy_pca, precision_pca, recall_pca, tp_pca, fp_pca, fn_pca, tn_pca = list(), list(), list(), list(), list(), list(), list()\n",
    "accuracy_arma, precision_arma, recall_arma, tp_arma, fp_arma, fn_arma, tn_arma = list(), list(), list(), list(), list(), list(), list()\n",
    "\n",
    "for i in range(7):\n",
    "    pca_acc, pca_prec, pca_rec, pca_tp, pca_fp, pca_fn, pca_tn = comp.performance(labels_true_pca,labels_pred_pca[i], False)\n",
    "    arma_acc, arma_prec, arma_rec, arma_tp, arma_fp, arma_fn, arma_tn = comp.performance(labels_true_arma,labels_pred_arma[i], False)\n",
    "    accuracy_pca.append(pca_acc)\n",
    "    accuracy_arma.append(arma_acc)\n",
    "    precision_pca.append(pca_prec)\n",
    "    precision_arma.append(arma_prec)\n",
    "    recall_pca.append(pca_rec)\n",
    "    recall_arma.append(arma_rec)\n",
    "    tp_pca.append(pca_tp)\n",
    "    tp_arma.append(2*arma_tp)\n",
    "    fp_pca.append(pca_fp)\n",
    "    fp_arma.append(2*arma_fp)\n",
    "    fn_pca.append(pca_fn)\n",
    "    fn_arma.append(2*arma_fn)\n",
    "    tn_pca.append(pca_tn)\n",
    "    tn_arma.append(2*arma_tn)\n",
    "\n",
    "print(\"\\nAverage performances:\")\n",
    "print(\" Accuracy PCA / ARMA:\", np.mean(accuracy_pca), \" / \", np.mean(accuracy_arma))\n",
    "print(\" Precision PCA / ARMA:\", np.mean(precision_pca), \" / \", np.mean(precision_arma))\n",
    "print(\" Recall PCA / ARMA:\", np.mean(recall_pca), \" / \", np.mean(recall_arma))\n",
    "print(\" TP PCA / ARMA:\", int(np.mean(tp_pca)), \" / \", int(np.mean(tp_arma)))\n",
    "print(\" FP PCA / ARMA:\", int(np.mean(fp_pca)), \" / \", int(np.mean(fp_arma)))\n",
    "print(\" FN PCA / ARMA:\", int(np.mean(fn_pca)), \" / \", int(np.mean(fn_arma)))\n",
    "print(\" TN PCA / ARMA:\", int(np.mean(tn_pca)), \" / \", int(np.mean(tn_arma)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the comparison of PCA and ARMA two measures are used: the number of distinct anomalous regions in which at least one anomaly is decected, and the basic performance metrics (accuracy, precision, recall, and confusion matrix). The anomalous regions are an important measure since it explains how many different anomalous attacks are detected. If we just count the number of detected anomalies, they can for instance all be for the same attack and therefore not a very effective anomaly detection mechanism. The higher the number of regions, the more effective the method. The second measure that is used are the standard machine learning metrics. We are interested in a high precision in combination with a high number of true positives (also depends on number of 'true' cases there are) and a high accuracy. This means there are just a few false positives and a good amount of true positives in the prediction. False positives in this context has the meaning of a false alarm, and are very much unwanted for the SCADA system. Upon receipt of an alarm, the floor managers will stop the system from running until they diagnosed and fixed the issue. If this happens often, a lot of time and money is lost and the possibility of neglecting the alarms will increase.\n",
    "\n",
    "The measures are exposed to both the PCA and ARMA methods by the use of the tank signals T1 to T7. One important note is that the PCA method used the training dataset 2 for the prediction and ARMA used the test dataset. This is of course not a direct comparison, but due to time constraints it wasn't possible to convert one of the methods with the new data. The datasets also differ in size, thus we increased the confusion matrix results to be equal in the total number of samples for a more equal evaluation, although this is of course not equal.\n",
    "\n",
    "If we now look at the numbers we can see that the number of regions is a lot higher for PCA than for ARMA. The precision and accuracy, as well as the number of TP, is also quite a lot higher for PCA. The number of FP is equal for both, while the number of false negatives (an alarm that never gone off) is almost double for ARMA than for PCA. We can conclude that based on these numbers the PCA method is clearly the better of the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 50 anomalies detected by the LOF and N-gram for the L_T1 signal and compare the results\n",
    "count = 0\n",
    "# For each signal check similartiy of both methods\n",
    "for c in range(len(top_LT_outliers)):\n",
    "    top_anomaly_L_T1_Ngram = plot_data[c]\n",
    "    \n",
    "    for i in sorted(top_LT_outliers[c]):\n",
    "        # Count 1 if anomaly is in both sets\n",
    "        if i in top_anomaly_L_T1_Ngram:\n",
    "            count += 1\n",
    "\n",
    "print(\"Amount of same anomalies detected for signal \" + str(test_signals[c]) + \": \"  + str(count) + \"50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the performance of the LOF and N-grams methods, the top-k detected anomalies are compared with each other. This measure is chosen because both methods already created a ordered list of detected anomalies. Therefore it was relatively easy to check the similarities of the results. \n",
    "\n",
    "The results of the algorithms is compared for three different signals: L_T1, L_T2, P_J302. As can be seen above, the methods find totally different anomalies. There are multiple reasons why this could happen. One reason could be the hyperparameters used in both methods. Another reason could be a fault in the implementation of one the algorithms. Also it could be that the algorithms find different anomalies, however, such a huge difference is not reasonable.\n",
    "\n",
    "Unfortunately the performance of the LOF algorithm could only be compared to the performance of the N-grams method because the assignment was interpreted in a different way between the team members."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Bonus Task 1 A4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7a. Provide implementation and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
